---
title: "Planning for near-free AI"
date: "2024-01-07"
author: "Ted Spare"
bannerImage: "/images/blog.webp"
description: "How trends in open-source large-language models are converging to usher in cheap, abundant intelligence. We examine the state of LLM capability, cost, and timeline."
---

# Planning for near-free AI

As AI models become more efficient and hardware costs continue to decrease, we're approaching a future where AI will be nearly free to use. This shift has profound implications for product development and business strategy.

## The economics of AI are changing

Just a few years ago, running large language models required significant computational resources and came with high costs. Today, we're seeing:

- **Dramatic efficiency improvements**: Models like GPT-4o-mini deliver impressive performance at a fraction of the computational cost of earlier models
- **Hardware optimization**: Specialized chips and infrastructure designed specifically for AI workloads
- **Economies of scale**: As more companies adopt AI, the cost per inference continues to drop

## What this means for product development

When AI becomes essentially free, product strategy needs to evolve:
