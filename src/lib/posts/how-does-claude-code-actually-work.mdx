import { AUTHORS, CATEGORIES } from '~/lib/constants/blog'
import { AgentLoopCards } from '~/ui/blog/claude-code/agent-loop-cards'
import { SystemArchitecture } from '~/ui/blog/claude-code/system-architecture'
import { ToolsTable } from '~/ui/blog/claude-code/tools-table'
import { Collapsible } from '~/ui/collapsible'
import { Caption, Figure } from '~/ui/figure'

export const metadata = {
  title: "How does Claude Code actually work?",
  date: "2026-02-10",
  subtitle: "A first-principles understanding of the most powerful coding agent",
  author: AUTHORS.SARIM_MALIK,
  bannerImageUrl: "/images/claude-code.png",
  category: CATEGORIES.BREAKDOWN,
  description: "Understanding Claude Code from first-principles to better understand system design for building intelligent applications"
}

Claude Code has quickly become the default coding agent since being [announced](https://www.anthropic.com/news/claude-3-7-sonnet) less than a year ago by Anthropic. 

If you’ve tried Claude Code, you’ve probably had the same reaction: wait, this actually works. And once you feel that, it’s easy to imagine agents like this spreading far beyond code.

Naturally, we became curious and wanted to understand how the system works, dig through the [Claude Code docs](https://code.claude.com/docs/en/overview) and study the [Claude Agent SDK](https://platform.claude.com/docs/en/agent-sdk/overview) (Claude Code’s API surface).

Claude Code is closed source, so we can’t inspect its internals directly. Instead, we have to infer the system from its public surface area, mainly the SDK and docs.

We had a few questions in mind:

- What’s the agent actually doing step-by-step?
- Is it a single-agent or multi-agent, and how are decisions made?
- Which tools does Claude Code use, and why are they designed the way they are?
- How does it run long conversations without losing the plot?

## What is Claude Code, really?

Claude Code is a [coding agent](https://docs.aws.amazon.com/prescriptive-guidance/latest/agentic-ai-patterns/coding-agents.html) which runs in your terminal. You can invoke it to tackle coding tasks, but you can also ask for help with non-coding tasks such as writing docs, searching files, researching topics, and more.

This seems to be emergent behaviour as it was [originally designed](https://youtu.be/zDmW5hJPsvQ?si=Lh9ZSEYFS6_RodVo&t=132) to be an internal coding agent for Anthropic, but quickly found product-market fit internally and eventually became a core offering of the company.

Much of Claude Code's capabilities can be attributed to the built-in agentic loop which alternates between three phases:

<Figure>
  <AgentLoopCards />
  <Caption>The phases Claude Code cycles through</Caption>
</Figure>

Now here’s the key idea: the loop stretches or shrinks based on what you ask. A small request might be “read once, answer, done.” A bigger request usually turns into a back-and-forth: read a bit, change something, check it, repeat until it’s correct.

Almost everything Claude Code does is one of three things: gather, act, or verify. Small tasks stop early. Bigger ones loop until they’re solid. 

## Where Claude Code sits in the landscape

Before we go deeper, it helps to understand what kind of system Claude Code is and how it compares to alternatives.

**What is an agent harness?**

*[...to add...]*

## The core system

Let’s zoom in on a single request. Claude Code doesn’t answer in one shot, it runs a tight transaction loop: decide what to do next, do it, then use the result as new evidence.

<Figure>
  <SystemArchitecture />
  <Caption>One request, many steps. The context window grows as Claude gathers, acts, and verifies.</Caption>
</Figure>

Here’s the flow:

1. **Start state**: your request, plus the current context window (system instructions, prior messages, recent tool results).
2. **Decision**: the model reads that state and chooses the next move, either answer now or call a tool to reduce uncertainty.
3. **Execution**: tools run in the terminal environment (read files, search, run commands) and return results.
4. **Update**: those results get appended back into the context window, and the loop repeats until Claude can stop confidently.

That’s the whole transaction: context → decide → tool → result → context, repeated until the evidence is strong enough.

## The model

At the center of Claude Code is Claude, the model. The model reads your project, keeps a mental map of how things connect, and decides what to do next.

Given what it sees in the context window, it chooses the next move: gather more context, take an action, or verify what changed.

The model tiers matter more than most users realize:

**Sonnet** is the default. It handles most coding tasks well—file navigation, straightforward edits, test runs. For 80% of work, it’s the right call.

**Opus** is where you go when the hard part is reasoning, not execution. Architecture decisions, debugging race conditions, refactors that touch many files, migrations where you need to hold a lot of state in your head. Opus is slower and costs more, but it makes fewer dumb mistakes on complex tasks. At Rubric, we use Opus as our daily driver—the unit cost is higher, but we get fewer loops and less rework.

**Haiku** is fast and cheap, but it loses nuance. Fine for grep-like tasks or simple lookups. Not great for multi-step reasoning.

**Extended thinking** is an option on any tier. You’re essentially asking the model to spend more compute before responding—longer internal chains of thought, more self-correction. This increases latency and cost, but it’s worth it for genuinely hard problems where “thinking longer” actually helps.

Today’s state of the art is **Sonnet 4.5** and **Opus 4.5**, and these models keep improving over time.

Next, let’s define what “the context window” actually contains.

## Context window: what Claude Code sees (and what it can’t)

The loop is powered by one constraint: whatever fits in the model’s context window is what exists for this step.

Claude doesn’t have magical access to your whole project. It only sees what Claude Code has loaded into the window right now, and as the window fills up, older details get compacted (more on this later).

So what’s inside the window?

- **System instructions**: the rules of the tool, plus your project rules (like `CLAUDE.md`).
  
- **Conversation history**: your messages and Claude’s responses.
- **Tool results**: file contents it read, search results, terminal output, diffs, failing tests, and anything else a tool returned.
- **Loaded skills and tool definitions**: extra capabilities you’ve enabled that Claude can call.

<Collapsible title={<>What is <code>CLAUDE.md</code></>}>
    <code>CLAUDE.md</code> is a plain markdown file you add to your project to tell Claude Code “here’s how we do things here”. Unlike conversation history, which is ephemeral, this is a set of fixed instructions always loaded into the context window.
</Collapsible>

<Collapsible title="What is a Skill?">
    A [Skill](https://code.claude.com/docs/en/skills) is a markdown file which containes reusable instructions. Claude loads a Skill only when it’s relevant (or when you invoke it directly).
</Collapsible>

That’s the “working set” Claude uses to decide the next action. Anything outside of it might as well not exist.

Now the practical part: your context budget depends on the model you pick. The latest models are all <a href="https://platform.claude.com/docs/en/about-claude/models/overview">200K tokens</a>, so model choice changes quality/latency/cost more than raw context size. Compared to older generations, that’s a lot: Claude jumped from <a href="https://www.anthropic.com/index/100k-context-windows">9K to 100K</a> in 2023, and then to <a href="https://www.anthropic.com/index/claude-2-1">200K</a> later that year.

When the window fills up, Claude Code manages it automatically: it clears older tool outputs first, then summarizes the conversation if needed. Your latest request usually survives, but early details can disappear, which is why persistent rules belong in `CLAUDE.md`. This process of condensing the context window is called context compaction.

Next up, let’s look at the tools that generate most of that evidence.

## Tools: the building blocks

When you ask Claude Code to do real work, it’s mostly using a small, sharp set of tools. Anthropic publishes the canonical list in the Claude Code docs under [Tools available to Claude](https://code.claude.com/docs/en/settings#tools-available-to-claude).

You can group the core tools into three buckets:

- **Workspace tools**: `Read`, `Write`, `Edit`, `Glob`, `Grep`, and `Bash` let Claude inspect your codebase and make changes in your terminal environment.
- **Web tools**: `WebSearch` and `WebFetch` let Claude pull in external context when the answer isn’t in your repo.
- **Interaction tool**: `AskUserQuestion` is how Claude gets unstuck when a required detail is missing.

Here are the core tools Claude Code uses most often in the gather/action/verify loop:

<Figure>
  <ToolsTable />
  <Caption>
    [Full tools list](https://code.claude.com/docs/en/settings#tools-available-to-claude)
  </Caption>
</Figure>

Beyond the core loop, Claude Code also has supporting tools that expand its surface area without changing the mental model:

- **Orchestration**: task and delegation helpers like `Task`, `TaskList`, and `TaskOutput`.
- **Integrations**: `MCPSearch` for [Model Context Protocol (MCP)](#mcp) tool discovery and loading.
- **Editing**: `NotebookEdit` for notebooks and `LSP` for language-server powered code intelligence.
- **Control utilities**: things like `ExitPlanMode` and `KillShell` to manage the session.

One subtle enabler here is tool search: instead of preloading a huge tool catalog (which can eat your context window), Claude can search for the right tool and load only what it needs on demand ([tool search](https://platform.claude.com/docs/en/agents-and-tools/tool-use/tool-search-tool)).

Under the hood, the [text editor tool](https://platform.claude.com/docs/en/agents-and-tools/tool-use/text-editor-tool) is a great example of the design philosophy here: edits are constrained. Instead of “rewrite this file”, Claude is limited to a small command set (`view`, `create`, `insert`, `str_replace`), and the core edit primitive, [str_replace](https://platform.claude.com/docs/en/agents-and-tools/tool-use/text-editor-tool#str-replace), requires an exact match (including whitespace) so the change is surgically targeted.

That constraint matters because it fails loudly: if the old snippet doesn’t exist, or appears multiple times, the tool returns an error. The agent is forced back into “gather”, which is exactly what you want when a change would otherwise be ambiguous.

Once you see the loop through that lens, a few things jump out.

First, `Bash` is what makes Claude Code feel “real”. Each command runs in your environment in a fresh shell, but the working directory and filesystem state carry forward, so sequences like “install deps → run tests → check diffs” operate on the same repo.

Second, the web tools are powerful. `WebSearch` is great for freshness (and comes with citations), while `WebFetch` is for pulling in full pages, but bear in mind that even a normal doc page can add thousands of tokens and seconds of waiting.

What’s most insightful about Claude Code isn’t any single tool, it’s the shape of the interfaces. The model is responsible for deciding what to do next and proposing a small, well-scoped action, but the tool layer is responsible for doing it safely: validating inputs, enforcing constraints, and returning errors when an action is ambiguous.

That’s a useful mental model when you design your own tools. Let the model generate the intent (which file, which command, which URL), and make your tools handle the mechanics (execution, guardrails, retries, truncation, and “fail loudly” behavior), so the agent spends tokens on reasoning instead of reinventing implementation details.

## Terminal as an environment

A huge part of Claude Code is the environment it lives in: your terminal, pointed at your project, with your tooling already wired up.

The terminal creates a clean permission boundary. Claude doesn’t get magic access, it inherits whatever your shell user can do, and every meaningful action routes through explicit tool calls you can audit, constrain, or deny.

Just as importantly, it lets Claude interact with the same primitives you already trust: files, diffs, tests, and commands. Claude isn’t inventing a new workflow, it’s orchestrating the one you already have.

That’s why the same agent in a generic cloud environment is often less effective. Without your project’s existing scripts, linters, and build/test commands, “take action” becomes guesswork, and “verify” becomes weak. Claude Code feels strong because the environment provides the primitives, and the model composes them.

## System optimizations

Claude Code’s baseline loop is simple, but real projects are not. These optimizations help the agent scale: doing more work (and deeper work) without flooding the main context window with every intermediate step, and without turning integrations into a pile of bespoke glue code.

### Sub-agents

Sub-agents are how Claude Code does more work without blowing up the main context window. Instead of forcing one agent to hold every intermediate thought and tool result, the main agent can spawn a separate agent instance for a focused subtask, then pull back a condensed result. Cursor [recently shipped](https://cursor.com/changelog/2-4) something similar—parallel, context-isolated work streams.

This helps in three ways:

- **Context isolation**: the sub-agent keeps its own context, so deep exploration doesn’t pollute the main thread.
- **Parallelism**: you can run multiple sub-agents at once (for example, “find files”, “check tests”, “review diffs”), then merge the outcomes.
- **Tool scoping**: sub-agents can be restricted to a smaller tool set (read-only review, test runner), which reduces risk.

The mental model is simple: the main agent stays “in charge” of the narrative and the final decision. Sub-agents are disposable workers that hand back a condensed result to the main agent the same way a tool returns output.

### MCP

The [Model Context Protocol (MCP)](https://platform.claude.com/docs/en/agent-sdk/mcp) is a standard way to plug external systems into an agent as tools, like GitHub, Slack, databases, browsers, and internal APIs.

MCP interacts with the context window in an unintuitive way: it’s not the tool results that usually hurt first, it’s the tool definitions. If you dump hundreds of tool schemas into the prompt, you spend your budget on plumbing instead of reasoning.

Claude’s approach is “load tools on demand”. In the Agent SDK, [MCP tool search](https://platform.claude.com/docs/en/agent-sdk/mcp#mcp-tool-search) can automatically defer loading tool definitions and only expand the ones Claude actually needs, keeping the active context focused on the task.

## Why this matters

Claude Code feels powerful because it’s a tight system, not a magic model. The agentic loop turns uncertainty into evidence, the context window is the scarce resource that forces discipline, and the tools are designed to be constrained enough that the model can’t “wing it” without paying for it in more reads.

The practical takeaway is that agent quality is mostly systems design. If you want an agent to be reliable, you need good primitives (files, tests, scripts, permissions), small tool interfaces, and a feedback loop that makes it cheap to verify and hard to hallucinate success.

This is also why “agents in the cloud” often disappoint. If the environment is generic, the agent can’t lean on your existing workflow, so it spends more tokens guessing and less time executing and verifying.

If you’re building your own agent, start here:

- **Design the environment first**: make “verify” easy (tests, linters, `git diff`) and safe (permissions, allowlists).
- **Constrain tools on purpose**: let the model choose the action, but let the tool enforce correctness and fail loudly.
- **Scale with isolation**: use sub-agents to keep context clean, and MCP when you need external systems without rewriting integrations.

If you want to go deeper, the best references are the [Agent SDK](https://platform.claude.com/docs/en/agent-sdk/overview) and the [Claude Code docs](https://code.claude.com/docs/en/how-claude-code-works).
